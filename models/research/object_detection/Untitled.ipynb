{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes: [[9.99802887e-01 9.99562800e-01 9.95484352e-01 9.89302337e-01\n",
      "  9.88344908e-01 9.87238646e-01 8.59761953e-01 8.18997979e-01\n",
      "  8.13684762e-01 1.93814307e-01 1.87675864e-01 1.19772911e-01\n",
      "  1.01677403e-01 7.23738521e-02 7.08346441e-02 5.02437092e-02\n",
      "  5.01096286e-02 4.75188121e-02 4.05380726e-02 3.13984044e-02\n",
      "  1.45784980e-02 1.09464098e-02 5.98512031e-03 5.63212810e-03\n",
      "  5.53403888e-03 5.34063112e-03 4.31735441e-03 2.83980556e-03\n",
      "  2.56591686e-03 2.49753427e-03 2.21516890e-03 1.56645919e-03\n",
      "  1.26970164e-03 1.18371204e-03 1.08071999e-03 9.97016206e-04\n",
      "  7.39617913e-04 6.30535185e-04 3.93702067e-04 2.51288497e-04\n",
      "  1.00347090e-04 7.82488933e-05 2.75196671e-05 2.53328162e-05\n",
      "  2.42135447e-05 1.61826774e-05 1.23080918e-05 1.18251091e-05\n",
      "  1.02101721e-05 7.87542831e-06 6.69879410e-06 6.33594254e-06\n",
      "  6.02238197e-06 4.87186480e-06 4.74711578e-06 3.93949313e-06\n",
      "  3.86196689e-06 2.83521899e-06 2.67423684e-06 2.01664375e-06\n",
      "  1.87978151e-06 1.73879050e-06 1.47021751e-06 1.31450815e-06\n",
      "  1.28182967e-06 1.15790601e-06 9.78337198e-07 9.32417890e-07\n",
      "  8.78832680e-07 7.79760171e-07 7.44472629e-07 5.37113806e-07\n",
      "  5.35082052e-07 4.47819673e-07 3.49992803e-07 3.39848015e-07\n",
      "  3.38305853e-07 3.27476641e-07 3.17701364e-07 3.06810477e-07\n",
      "  3.03659988e-07 2.77027766e-07 2.50255766e-07 2.37169189e-07\n",
      "  2.30175871e-07 2.15662226e-07 2.10505604e-07 2.09746219e-07\n",
      "  1.97550165e-07 1.88257303e-07 1.65719214e-07 1.47861613e-07\n",
      "  1.46503353e-07 1.16616988e-07 1.15412078e-07 1.14541727e-07\n",
      "  1.12727477e-07 1.06643824e-07 1.03983361e-07 8.86147120e-08\n",
      "  8.75307151e-08 7.14588708e-08 5.92969904e-08 5.66949225e-08\n",
      "  5.24758512e-08 5.18173238e-08 5.10670262e-08 4.92075323e-08\n",
      "  4.59820910e-08 4.37121024e-08 4.31837499e-08 4.00103133e-08\n",
      "  3.95522086e-08 3.75363527e-08 3.73161271e-08 2.82802990e-08\n",
      "  2.31469528e-08 2.26004637e-08 2.19024514e-08 2.11895053e-08\n",
      "  2.09395665e-08 1.72584702e-08 1.72438774e-08 1.60758820e-08\n",
      "  1.56721818e-08 1.38790126e-08 1.35503209e-08 1.31755122e-08\n",
      "  1.31476305e-08 1.25880799e-08 1.24986013e-08 1.24821167e-08\n",
      "  1.13750502e-08 1.00923554e-08 9.94256766e-09 9.66381020e-09\n",
      "  9.48841627e-09 8.21158697e-09 8.12521250e-09 7.98188360e-09\n",
      "  7.69184272e-09 7.10688841e-09 7.04671521e-09 6.94589986e-09\n",
      "  6.76333212e-09 6.72285561e-09 5.98926464e-09 5.71238257e-09\n",
      "  5.68966030e-09 5.56908608e-09 5.29882938e-09 5.27672928e-09\n",
      "  5.25713340e-09 5.15765075e-09 4.91828356e-09 4.61379157e-09\n",
      "  4.04118472e-09 3.92524369e-09 3.83722210e-09 3.57354368e-09\n",
      "  2.52127763e-09 2.34736075e-09 2.21032948e-09 2.12231877e-09\n",
      "  2.09079465e-09 1.96124850e-09 1.85892113e-09 1.62928182e-09\n",
      "  1.58861291e-09 1.52260804e-09 1.33663924e-09 1.26034250e-09\n",
      "  1.21416510e-09 1.14054821e-09 1.09291176e-09 1.07027753e-09\n",
      "  1.05973297e-09 9.85269644e-10 9.67588565e-10 8.77410755e-10\n",
      "  8.73608408e-10 8.49616377e-10 7.82839127e-10 6.65822952e-10\n",
      "  6.46773357e-10 6.16366069e-10 5.82507265e-10 5.27830668e-10\n",
      "  5.02005160e-10 4.99437991e-10 4.06091327e-10 4.02477912e-10\n",
      "  3.57594565e-10 3.41682183e-10 3.29701849e-10 3.29670402e-10\n",
      "  2.45467813e-10 1.94592939e-10 1.90932575e-10 1.67507244e-10\n",
      "  1.32498013e-10 8.69059269e-11 8.20221807e-11 6.11022344e-11\n",
      "  6.06028006e-11 5.70434533e-11 5.08427363e-11 4.87477593e-11\n",
      "  4.20811858e-11 4.19623225e-11 3.94756311e-11 3.04463364e-11\n",
      "  3.01585076e-11 2.63874807e-11 2.63783231e-11 1.86491742e-11\n",
      "  1.74946672e-11 1.46758959e-11 1.25458498e-11 1.23436669e-11\n",
      "  1.22610706e-11 1.21506043e-11 1.15595207e-11 9.96031209e-12\n",
      "  8.57383869e-12 7.76350772e-12 7.22310579e-12 6.33019331e-12\n",
      "  5.21795194e-12 5.18705174e-12 4.31607614e-12 3.12840574e-12\n",
      "  2.28613786e-12 1.94889894e-12 1.00081055e-12 3.93604095e-13\n",
      "  3.25844657e-13 2.77359028e-13 2.22533770e-13 1.05278233e-13\n",
      "  8.54964496e-14 5.19209445e-14 2.58077590e-14 2.23155912e-14\n",
      "  1.32600391e-14 1.48190680e-15 5.62301022e-16 3.73933448e-17\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "######## Image Object Detection Using Tensorflow-trained Classifier #########\n",
    "#\n",
    "#\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# Import utilites\n",
    "from utils import label_map_util\n",
    "from utils import visualization_utils as vis_util\n",
    "\n",
    "# Name of the directory containing the object detection module we're using\n",
    "MODEL_NAME = 'inference_graph'\n",
    "IMAGE_NAME = 'test1.jpg'\n",
    "\n",
    "# Grab path to current working directory\n",
    "CWD_PATH = os.getcwd()\n",
    "\n",
    "# Path to frozen detection graph .pb file, which contains the model that is used\n",
    "# for object detection.\n",
    "PATH_TO_CKPT = os.path.join(CWD_PATH,MODEL_NAME,'frozen_inference_graph.pb')\n",
    "\n",
    "# Path to label map file\n",
    "PATH_TO_LABELS = os.path.join(CWD_PATH,'training','labelmap.pbtxt')\n",
    "\n",
    "# Path to image\n",
    "PATH_TO_IMAGE = os.path.join(CWD_PATH,IMAGE_NAME)\n",
    "\n",
    "# Number of classes the object detector can identify\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "# Load the label map.\n",
    "# Label maps map indices to category names, so that when our convolution\n",
    "# network predicts `5`, we know that this corresponds to `king`.\n",
    "# Here we use internal utility functions, but anything that returns a\n",
    "# dictionary mapping integers to appropriate string labels would be fine\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "# Load the Tensorflow model into memory.\n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "    sess = tf.Session(graph=detection_graph)\n",
    "\n",
    "# Define input and output tensors (i.e. data) for the object detection classifier\n",
    "\n",
    "# Input tensor is the image\n",
    "image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "# Output tensors are the detection boxes, scores, and classes\n",
    "# Each box represents a part of the image where a particular object was detected\n",
    "detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "\n",
    "# Each score represents level of confidence for each of the objects.\n",
    "# The score is shown on the result image, together with the class label.\n",
    "detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "\n",
    "# Number of objects detected\n",
    "num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "# Load image using OpenCV and\n",
    "# expand image dimensions to have shape: [1, None, None, 3]\n",
    "# i.e. a single-column array, where each item in the column has the pixel RGB value\n",
    "image = cv2.imread(PATH_TO_IMAGE)\n",
    "image_expanded = np.expand_dims(image, axis=0)\n",
    "\n",
    "# Perform the actual detection by running the model with the image as input\n",
    "(boxes, scores, classes, num) = sess.run(\n",
    "    [detection_boxes, detection_scores, detection_classes, num_detections],\n",
    "    feed_dict={image_tensor: image_expanded})\n",
    "\n",
    "# Draw the results of the detection (aka 'visulaize the results')\n",
    "\n",
    "vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "    image,\n",
    "    np.squeeze(boxes),\n",
    "    np.squeeze(classes).astype(np.int32),\n",
    "    np.squeeze(scores),\n",
    "    category_index,\n",
    "    use_normalized_coordinates=True,\n",
    "    line_thickness=8,\n",
    "    min_score_thresh=0.80)\n",
    "\n",
    "# All the results have been drawn on image. Now display the image.\n",
    "cv2.imshow('Object detector', image)\n",
    "cv2.imwrite('image.png',image)\n",
    "\n",
    "\n",
    "# Press any key to close the image\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Clean up\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['box':boxes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
